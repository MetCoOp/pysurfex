#!/usr/bin/env python3

import surfex
import sys
import argparse
import os
import json


def parse():
    """Parse the command line input arguments."""
    parser = argparse.ArgumentParser(description="SURFEX for MASTERRODB")

    parser.add_argument('--version', action='version', version='surfex {0}'.format(surfex.__version__))
    parser.add_argument('--wrapper', '-w', type=str, default="", help="Execution wrapper command")
    parser.add_argument('--json', '-j', type=str, nargs="?", required=True, help="A JSON file with run options")
    parser.add_argument('--pgd', type=str, nargs="?", required=True, help="Name of the PGD file")
    parser.add_argument('--prep', type=str, nargs="?", required=True, help="Name of the PREP file")
    parser.add_argument('--force', '-f', action="store_true", help="Force re-creation")
    parser.add_argument('--rte', '-r', required=True, nargs='?')
    parser.add_argument('--ecoclimap', '-e', required=True, nargs='?')
    parser.add_argument('--domain', '-d', required=True, type=str, help="JSON file with domain")
    parser.add_argument('--output', '-o', required=True, nargs='?')
    parser.add_argument('--input', '-i', required=False, default=None, nargs='?', help="JSON file with input")
    parser.add_argument('--archive', '-a', required=False, default=None, nargs='?',
                        help="JSON file with archive output")
    parser.add_argument('--binary', '-b', required=False, default=None, nargs='?', help="Full path of MASTERODB binary")
    parser.add_argument('--assim_input', required=False, default=None, nargs='?', help="JSON file with assimilation input")
    parser.add_argument('--assim_output', required=False, default=None, nargs='?', help="JSON file with assimilation output")

    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit()

    args = parser.parse_args()
    return args.binary, args.rte, args.wrapper, args.json, args.force, args.output, args.input, args.ecoclimap, \
        args.domain, args.archive, args.pgd, args.prep, args.assim_input, args.assim_output


if __name__ == "__main__":

    binary, rte, wrapper, json_file, force, output, input_arg, ecoclimap, domain, archive, pgd_file_path, \
        prep_file_path, assim_input, assim_output = parse()

    if os.path.exists(rte):
        my_batch = surfex.BatchJob(json.load(open(rte, "r")), wrapper=wrapper)
    else:
        raise FileNotFoundError

    if os.path.exists(domain):
        my_domain = json.load(open(domain, "r"))
    else:
        raise FileNotFoundError

    if os.path.exists(json_file):
        json_settings = json.load(open(json_file, "r"))
    else:
        raise FileNotFoundError

    if os.path.exists(domain):
        my_geo = surfex.json2geo(json.load(open(domain, "r")))
        print(my_geo)
    else:
        raise FileNotFoundError

    if os.path.exists(ecoclimap):
        ecoclimap_file = ecoclimap
    else:
        raise FileNotFoundError

    my_input = None
    if input_arg is not None:
        if os.path.exists(input_arg):
            my_input = surfex.JsonInputDataFromFile(input_arg)
        else:
            raise FileNotFoundError

    my_archive = None
    if archive is not None:
        if os.path.exists(archive):
            my_archive = surfex.JsonOutputDataFromFile(archive)
        else:
            raise FileNotFoundError

    if assim_input is not None:
        if os.path.exists(assim_input):
            assim_input = surfex.JsonInputDataFromFile(assim_input)
        else:
            raise FileNotFoundError

    if assim_output is not None:
        if os.path.exists(assim_output):
            assim_output = surfex.JsonInputDataFromFile(assim_output)
        else:
            raise FileNotFoundError

    if assim_input is not None or assim_output is not None:
        assim = surfex.Assimilation(ass_input=assim_input, ass_output=assim_output)

    my_settings = surfex.ascii2nml(json_settings)
    # my_geo.update_namelist(my_settings)
    my_ecoclimap = surfex.JsonInputDataFromFile(ecoclimap_file)

    print(my_settings)
    my_format = my_settings["NAM_IO_OFFLINE"]["CSURF_FILETYPE"]
    my_pgdfile = my_settings["NAM_IO_OFFLINE"]["CPGDFILE"]
    my_prepfile = my_settings["NAM_IO_OFFLINE"]["CPREPFILE"]
    my_surffile = my_settings["NAM_IO_OFFLINE"]["CSURFFILE"]

    # Only do archiving
    if binary is None and archive is not None:
        my_pgdfile = surfex.file.PGDFile(my_format, my_pgdfile, my_geo)
        my_prepfile = surfex.PREPFile(my_format, my_prepfile, my_geo)
        surffile = surfex.PREPFile(my_format, my_surffile, my_geo, archive_file=output)
        masterodb = surfex.Masterodb(my_settings, my_batch, my_pgdfile, my_prepfile, surffile, my_ecoclimap,
                                     assim=assim, binary=binary, input=my_input, print_namelist=True)
        masterodb.archive_output()

    else:
        # Normal dry or wet run
        if not os.path.exists(output) or force:

            print(my_settings)
            my_pgdfile = surfex.file.PGDFile(my_format, my_pgdfile, my_geo, input_file=pgd_file_path)
            my_prepfile = surfex.PREPFile(my_format, my_prepfile, my_geo, input_file=prep_file_path)
            print(my_format)
            surffile = surfex.PREPFile(my_format, my_surffile, my_geo, archive_file=output)
            print(my_surffile)
            masterodb = surfex.Masterodb(my_settings, my_batch, my_pgdfile, my_prepfile, surffile, my_ecoclimap,
                                         assim=assim, binary=binary, input=my_input, archive=my_archive,
                                         print_namelist=True)

            # Archive output
            if binary is not None:
                masterodb.archive_output()
        else:
            print(output + " already exists!")
